# -*- coding: utf-8 -*-
"""ModeleElephant (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HQXqSpK2_StSZPCtHH_WX6aZBjTXHWmM

## Installation

Avant de commencer, il est nécessaire de déjà posséder dans son environnement toutes les librairies utiles. Dans la seconde cellule nous importons toutes les librairies qui seront utiles à ce notebook. Il se peut que, lorsque vous lanciez l'éxecution de cette cellule, une soit absente. Dans ce cas il est nécessaire de l'installer. Pour cela dans la cellule suivante utiliser la commande :  

*! pip install nom_librairie*  

**Attention :** il est fortement conseillé lorsque l'une des librairies doit être installer de relancer le kernel de votre notebook.

**Remarque :** même si toutes les librairies sont importées dès le début, les librairies utiles pour des fonctions présentées au cours de ce notebook sont ré-importées de manière à indiquer d'où elles viennent et ainsi faciliter la réutilisation de la fonction dans un autre projet.
"""

# utiliser cette cellule pour installer les librairies manquantes
# pour cela il suffit de taper dans cette cellule : !pip install nom_librairie_manquante
# d'exécuter la cellule et de relancer la cellule suivante pour voir si tout se passe bien
# recommencer tant que toutes les librairies ne sont pas installées ...

# sous Colab il faut déjà intégrer ces deux librairies

#!pip install umap-learn[plot]
#!pip install holoviews
#!pip install -U ipykernel
#!pip install opencv-python

# eventuellement ne pas oublier de relancer le kernel du notebook

# Commented out IPython magic to ensure Python compatibility.
#@title
# Importation des différentes librairies utiles pour le notebook

# Tensorboard
# Load the TensorBoard notebook extension
# %load_ext tensorboard
from tensorflow.keras.callbacks import TensorBoard
import datetime

# Clear any logs from previous runs
!rm -rf ./logs/ 

log_dir = "logs/fit/" + datetime.datetime.now().strftime("%Y%m%d-%H%M%S")
tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)

#Sickit learn met régulièrement à jour des versions et 
#indique des futurs warnings. 
#ces deux lignes permettent de ne pas les afficher.
import warnings
warnings.filterwarnings("ignore", category=FutureWarning)

# librairies générales
import pickle 
import pandas as pd
from scipy.stats import randint
import numpy as np
import string
import time
import base64
import re
import sys
import copy
import random
from numpy import mean
from numpy import std


# librairie affichage
import matplotlib.pyplot as plt
import seaborn as sns
from PIL import Image
import plotly.graph_objs as go
import plotly.offline as py

from sklearn.metrics import confusion_matrix
from sklearn.manifold import TSNE
from sklearn.decomposition import PCA
from sklearn.model_selection import KFold
from sklearn.model_selection import cross_val_score
from sklearn.pipeline import Pipeline
from sklearn.naive_bayes import GaussianNB
from sklearn.metrics import accuracy_score

# TensorFlow et keras
import tensorflow as tf
from keras import layers
from keras import models
from keras import optimizers
from keras.preprocessing.image import ImageDataGenerator
from keras.utils import img_to_array, load_img
from keras.callbacks import ModelCheckpoint, EarlyStopping
import keras
from keras.models import Sequential
from keras.layers import Dense, Dropout, Flatten
from keras.layers import Conv2D, MaxPooling2D
from keras.preprocessing import image
from tqdm import tqdm
from keras.models import load_model
from sklearn.model_selection import KFold
from keras.datasets import fashion_mnist
from tensorflow.keras.utils import to_categorical
from keras.models import Sequential
from keras.layers import Conv2D
from keras.layers import MaxPooling2D
from keras.layers import Dense
from keras.layers import Flatten
from tensorflow.keras.optimizers import SGD
import os
from os import listdir
from os.path import isfile, join
import cv2
import glob

def plot_curves_confusion (history,confusion_matrix,class_names):
  plt.figure(1,figsize=(16,6))
  plt.gcf().subplots_adjust(left = 0.125, bottom = 0.2, right = 1,
                          top = 0.9, wspace = 0.25, hspace = 0)

  # division de la fenêtre graphique en 1 ligne, 3 colonnes,
  # graphique en position 1 - loss fonction

  plt.subplot(1,3,1)
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('model loss')
  plt.ylabel('loss')
  plt.xlabel('epoch')
  plt.legend(['Training loss', 'Validation loss'], loc='upper left')
  # graphique en position 2 - accuracy
  plt.subplot(1,3,2)
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('model accuracy')
  plt.ylabel('accuracy')
  plt.xlabel('epoch')
  plt.legend(['Training accuracy', 'Validation accuracy'], loc='upper left')
  
  # matrice de correlation
  plt.subplot(1,3,3)
  sns.heatmap(confusion_matrix,annot=True,fmt="d",cmap='Blues',xticklabels=class_names, yticklabels=class_names)# label=class_names)
  # labels, title and ticks
  plt.xlabel('Predicted', fontsize=12)
  #plt.set_label_position('top') 
  #plt.set_ticklabels(class_names, fontsize = 8)
  #plt.tick_top()
  plt.title("Correlation matrix")
  plt.ylabel('True', fontsize=12)
  #plt.set_ticklabels(class_names, fontsize = 8)
  plt.show()


def plot_curves(histories):
    plt.figure(1,figsize=(16,6))
    plt.gcf().subplots_adjust(left = 0.125, bottom = 0.2, right = 1,
                          top = 0.9, wspace = 0.25, hspace = 0)
    for i in range(len(histories)):
    	# plot loss
    	plt.subplot(121)
    	plt.title('Cross Entropy Loss')
    	plt.plot(histories[i].history['loss'], color='blue', label='train')
    	plt.plot(histories[i].history['val_loss'], color='red', label='test')  
    	plt.ylabel('loss')
    	plt.xlabel('epoch')
    	plt.legend(['Training loss', 'Validation loss'], loc='upper left')
    	# plot accuracy
    	plt.subplot(122)
    	plt.title('Classification Accuracy')
    	plt.ylabel('accuracy')
    	plt.xlabel('epoch')
    	plt.plot(histories[i].history['accuracy'], color='blue', label='train')
    	plt.plot(histories[i].history['val_accuracy'], color='red', label='test')
    	plt.legend(['Training accuracy', 'Validation accuracy'], loc='upper left')
    plt.show()

"""Pour pouvoir sauvegarder sur votre répertoire Google Drive, il est nécessaire de fournir une autorisation. Pour cela il suffit d'éxecuter la ligne suivante et de saisir le code donné par Google."""

# pour monter son drive Google Drive local
from google.colab import drive
drive.mount('/content/gdrive')

"""Corriger éventuellement la ligne ci-dessous pour mettre le chemin vers un répertoire spécifique dans votre répertoire Google Drive : """

# Commented out IPython magic to ensure Python compatibility.
import sys
my_local_drive='/content/gdrive/My Drive/Colab Notebooks/ML_FDS'

# Ajout du path pour les librairies, fonctions et données
sys.path.append(my_local_drive)
# Se positionner sur le répertoire associé
# %cd $my_local_drive

# %pwd

"""####Les jeux de données

Récupération des jeux de données :
"""

!wget https://www.lirmm.fr/~poncelet/Ressources/Tiger-Fox-Elephant.zip

import zipfile
with zipfile.ZipFile("Tiger-Fox-Elephant.zip","r") as zip_ref:
    zip_ref.extractall("Data_Project")

"""
Il y a trois jeux de données différents : des tigres, des éléphants et des renards. Pour chacun d'entre eux il y a un ensemble d'images positive et un ensemble d'images négatives. Par exemple dans le répertoire *tiger* il n'y a que des images de tigre et dans le répertoire *Tiger_negative_class* il n'y a que des images d'animaux qui ne correspondent pas à des tigres.   

Le code ci-dessous permet de visualiser quelques images contenues dans le répertoire *elephant*. """

for type_image in ["tiger","fox","elephant"]:
  mypath='Data_Project/Tiger-Fox-Elephant/'+type_image
  onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]
  images = np.empty(len(onlyfiles), dtype=object)
  for n in range(0, len(onlyfiles)):
    images[n] = cv2.imread( join(mypath,onlyfiles[n]) )


  COLUMNS = 25 # Nombre d'images à afficher

  plt.figure(figsize=(15,15))
  for i in range(COLUMNS):
      plt.subplot(5,5,i+1)
      plt.xticks([])
      plt.yticks([])
      plt.grid(False)
      # cv2 lit met les images en BGR et matplotlib lit du RGB
      # il faut donc convertir pour afficher les bonnes couleurs
      images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)
      plt.imshow(images[i],cmap=plt.cm.binary)  
      plt.xlabel('taille ' + str(images[i].shape))

"""Nous pouvons constater que les images ne sont pas de la même taille. Il faut donc les convertir. Une manière simple de faire et de faire la conversion lors de la lecture des images : ici nous convertissons toutes les images en 124x124."""

IMG_SIZE=124
for type_image in ["tiger","fox","elephant"]:
  mypath='Data_Project/Tiger-Fox-Elephant/'+type_image
  onlyfiles = [ f for f in listdir(mypath) if isfile(join(mypath,f)) ]
  images = np.empty(len(onlyfiles), dtype=object)
  for n in range(0, len(onlyfiles)):
    images[n] = cv2.imread( join(mypath,onlyfiles[n]) )
    images[n]  = cv2.resize(images[n], (IMG_SIZE, IMG_SIZE))

  plt.figure(figsize=(15,15))
  for i in range(COLUMNS):
      plt.subplot(5,5,i+1)
      plt.xticks([])
      plt.yticks([])
      plt.grid(False)
      # cv2 lit met les images en BGR et matplotlib lit du RGB
      # il faut donc convertir pour afficher les bonnes couleurs
      images[i] = cv2.cvtColor(images[i], cv2.COLOR_BGR2RGB)
      plt.imshow(images[i],cmap=plt.cm.binary)  
      plt.xlabel('taille ' + str(images[i].shape))

"""**Créer le jeu de données**   

Actuellement pour chaque animal nous avons un répertoire qui contient des images positives et un répertoire qui contient des images négatives. Pour pouvoir créer un jeu de données nous devons obtenir X et y. Les fonctions ci-dessous permettent de générer, à partir des répertoires, un jeu de données aléatoire pour X et y.
"""

def create_training_data(path_data, list_classes):
  training_data=[]
  for classes in list_classes:
      path=os.path.join(path_data, classes)
      class_num=list_classes.index(classes)
      for img in os.listdir(path):
        try:
          img_array = cv2.imread(os.path.join(path,img), cv2.IMREAD_UNCHANGED)
          new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))
          training_data.append([new_array, class_num])
        except Exception as e:
          pass  
  return training_data    

def create_X_y (path_data, list_classes):
      # récupération des données
      training_data=create_training_data(path_data, list_classes)
      # tri des données
      random.shuffle(training_data)
      # création de X et y
      X=[]
      y=[]
      for features, label in training_data:
        X.append(features)
        y.append(label)
      X=np.array(X).reshape(-1,IMG_SIZE, IMG_SIZE, 3)
      y=np.array(y)
      return X,y

def plot_examples(X,y):
  plt.figure(figsize=(15,15))
  for i in range(COLUMNS):
    plt.subplot(5,5,i+1)
    plt.xticks([])
    plt.yticks([])
    plt.grid(False)
    # cv2 lit met les images en BGR et matplotlib lit du RGB
    X[i] = cv2.cvtColor(X[i], cv2.COLOR_BGR2RGB)
    plt.imshow(X[i]/255.,cmap=plt.cm.binary)
    plt.xlabel('classe ' + str(y[i]))

"""Définition de constante globale      

"""

# constantes globales

IMG_SIZE=124
COLUMNS = 25 # Nombre d'images à afficher

"""Pour les éléphants :     """

my_path="Data_Project/Tiger-Fox-Elephant/"
all_classes = [['elephant','Elephant_negative_class'],['tiger','Tiger_negative_class'],['fox','Fox_negative_class']]

my_classes=all_classes[0]
X,y=create_X_y (my_path,my_classes)
print ("Nombre de données : ",X.shape[0])
print ("Taille d'une image pour connaître l'input du réseau", X[0].shape)
print ("Distribution des labels dans le jeu d'apprentissage")
sns.countplot(np.array(y))
plt.title("Nombre d'éléments par classe")
# affichage
plot_examples(X,y)

# Surtout ne pas oublier de normaliser les données avec :
X=X.astype('float')
X=X/255.0

X_elephant = copy.deepcopy(X)
y_elephant = copy.deepcopy(y)

my_classes=all_classes[1]
X,y=create_X_y (my_path,my_classes)
print ("Nombre de données : ",X.shape[0])
print ("Taille d'une image pour connaître l'input du réseau", X[0].shape)
print ("Distribution des labels dans le jeu d'apprentissage")
sns.countplot(np.array(y))
plt.title("Nombre d'éléments par classe")
# affichage
plot_examples(X,y)

# Surtout ne pas oublier de normaliser les données avec :
X=X.astype('float')
X=X/255.0

X_tiger = copy.deepcopy(X)
y_tiger = copy.deepcopy(y)

my_classes=all_classes[2]
X,y=create_X_y (my_path,my_classes)
print ("Nombre de données : ",X.shape[0])
print ("Taille d'une image pour connaître l'input du réseau", X[0].shape)
print ("Distribution des labels dans le jeu d'apprentissage")
sns.countplot(np.array(y))
plt.title("Nombre d'éléments par classe")
# affichage
plot_examples(X,y)

# Surtout ne pas oublier de normaliser les données avec :
X=X.astype('float')
X=X/255.0

X_fox = copy.deepcopy(X)
y_fox = copy.deepcopy(y)

"""##Modèle Baseline (CNN basique)
---

###Paramètres:
"""

n_folds=3
epochs=50
batch_size=16

"""### Model éléphant:"""

# Concaténation du jeu d'apprentissage et de test
inputs = X_elephant
targets = y_elephant
print(inputs.shape)
print(targets.shape)

# Evaluation avec un k-fold
def evaluate_model_elephant(dataX, dataY, n_folds=5, epochs=10, batch_size=32):
  scores, histories = list(), list()
  model = define_model_elephant()
  kfold = KFold(n_folds, shuffle=True, random_state=1)
  # parcourir les splits du k-fold
  for train_ix, test_ix in kfold.split(dataX):
    model = define_model_elephant()
    # selection des données
    X_train, y_train, X_test, y_test = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]
    # fit du modele
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
    # evaluate du modele
    loss, acc = model.evaluate(X_test, y_test, verbose=0)
    print('accuracy %.3f' % (acc * 100.0))
    scores.append(acc)
    histories.append(history)
  return scores, histories

# definition du premier modèle baseline
def define_model_elephant():
  model_elephant = Sequential()
  # Convolution and pooling
  model_elephant.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_1", padding="same", strides=1))
  model_elephant.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_1"))
  model_elephant.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_2", padding="same", strides=1))
  model_elephant.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_2"))
  model_elephant.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_3", padding="same", strides=1))
  model_elephant.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_3"))
  model_elephant.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_4", padding="same", strides=1))
  model_elephant.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_4"))
 


  # flatten
  model_elephant.add(Flatten(name="flatten") )

  # Partie classification
  # model_elephant.add(Dense(100, activation='relu'))
  model_elephant.add(Dense(1, activation='sigmoid'))

  model_elephant.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])
    
  return model_elephant

# fonction pour charger, transformer et évaluer le modele
# elle lance n-folds fois l'évaluation et affiche les courbes et résultats
def run_evaluation_elephant(n_folds, epochs, batch_size):
	# evaluate model
	scores, histories = evaluate_model_elephant(inputs, targets, n_folds, epochs, batch_size)
	plot_curves(histories)
	print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))



run_evaluation_elephant(n_folds, epochs, batch_size)

"""### Model tigre:"""

# Concaténation du jeu d'apprentissage et de test
inputs = X_tiger
targets = y_tiger
print(inputs.shape)
print(targets.shape)

# Evaluation avec un k-fold
def evaluate_model_tiger(dataX, dataY, n_folds=5, epochs=10, batch_size=32):
  scores, histories = list(), list()
  model = define_model_tiger()
  kfold = KFold(n_folds, shuffle=True, random_state=1)
  # parcourir les splits du k-fold
  for train_ix, test_ix in kfold.split(dataX):
    model = define_model_tiger()
    # selection des données
    X_train, y_train, X_test, y_test = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]
    # fit du modele
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
    # evaluate du modele
    loss, acc = model.evaluate(X_test, y_test, verbose=0)
    print('accuracy %.3f' % (acc * 100.0))
    scores.append(acc)
    histories.append(history)
  return scores, histories

# definition du premier modèle baseline
def define_model_tiger():
  model_tiger = Sequential()
  # Convolution and pooling
  model_tiger.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_1", padding="same", strides=1))
  model_tiger.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_1"))

  model_tiger.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_2", padding="same", strides=1))
  model_tiger.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_2"))

  model_tiger.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_3", padding="same", strides=1))
  model_tiger.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_3"))

  model_tiger.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_4", padding="same", strides=1))
  model_tiger.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_4"))



  # flatten
  model_tiger.add(Flatten(name="flatten") )

  # Partie classification
  model_tiger.add(Dense(1, activation='sigmoid'))

  model_tiger.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])
    
  return model_tiger

# fonction pour charger, transformer et évaluer le modele
# elle lance n-folds fois l'évaluation et affiche les courbes et résultats
def run_evaluation_tiger(n_folds, epochs, batch_size):
	# evaluate model
	scores, histories = evaluate_model_tiger(inputs, targets, n_folds, epochs, batch_size)
	plot_curves(histories)
	print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))



run_evaluation_tiger(n_folds, epochs, batch_size)

"""### Model renard:"""

# Concaténation du jeu d'apprentissage et de test
inputs = X_fox
targets = y_fox
print(inputs.shape)
print(targets.shape)

# Evaluation avec un k-fold
def evaluate_model_fox(dataX, dataY, n_folds=5, epochs=10, batch_size=32):
  scores, histories = list(), list()
  model = define_model_fox()
  kfold = KFold(n_folds, shuffle=True, random_state=1)
  # parcourir les splits du k-fold
  for train_ix, test_ix in kfold.split(dataX):
    model = define_model_fox()
    # selection des données
    X_train, y_train, X_test, y_test = dataX[train_ix], dataY[train_ix], dataX[test_ix], dataY[test_ix]
    # fit du modele
    history = model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_test, y_test), verbose=1)
    # evaluate du modele
    loss, acc = model.evaluate(X_test, y_test, verbose=0)
    print('accuracy %.3f' % (acc * 100.0))
    scores.append(acc)
    histories.append(history)
  return scores, histories

# definition du premier modèle baseline
def define_model_fox():
  model_fox = Sequential()
  # Convolution and pooling
  model_fox.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_1", padding="same", strides=1))
  model_fox.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_1"))
  
  model_fox.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_2", padding="same", strides=1))
  model_fox.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_2"))

  model_fox.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_3", padding="same", strides=1))
  model_fox.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_3"))

  model_fox.add(Conv2D(filters=32, kernel_size=(2,2), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3), name="Conv2D_4", padding="same", strides=1))
  model_fox.add(MaxPooling2D(pool_size=(2, 2), name="Maxpooling2D_4"))




  # flatten
  model_fox.add(Flatten(name="flatten") )

  # Partie classification
  model_fox.add(Dense(1, activation='sigmoid'))

  model_fox.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])
    
  return model_fox

# fonction pour charger, transformer et évaluer le modele
# elle lance n-folds fois l'évaluation et affiche les courbes et résultats
def run_evaluation_fox(n_folds, epochs, batch_size):
	# evaluate model
	scores, histories = evaluate_model_fox(inputs, targets, n_folds, epochs, batch_size)
	plot_curves(histories)
	print('Accuracy: mean=%.3f std=%.3f, n=%d' % (mean(scores)*100, std(scores)*100, len(scores)))



run_evaluation_fox(n_folds, epochs, batch_size)

"""#Sauvegarde des models




"""

model = define_model_elephant()
model.summary()
model = define_model_tiger()
model.summary()
model = define_model_fox()
model.summary()

# Save model elephant
final_model = define_model_elephant()
final_model.fit(inputs, targets, epochs=epochs, batch_size=batch_size, verbose=1)
final_model.save("modelebaselineElephant.h5", save_format='h5')

# Save model tigre
final_model = define_model_tiger()
final_model.fit(inputs, targets, epochs=epochs, batch_size=batch_size, verbose=1)
final_model.save("modelebaselineTiger.h5", save_format='h5')

# Save model fox
final_model = define_model_fox()
final_model.fit(inputs, targets, epochs=epochs, batch_size=batch_size, verbose=1)
final_model.save("modelebaselineFox.h5", save_format='h5')

"""# Augmentation du nombre d'images"""

from keras.preprocessing.image import ImageDataGenerator
datagen = ImageDataGenerator(
        rotation_range=20, # angle de rotation entre -20 et +20 degrés
        width_shift_range=0.1, # décalage horizontal entre -10% et +10% de la largeur de l'image
        height_shift_range=0.1, # décalage vertical entre -10% et +10% de la hauteur de l'image
        zoom_range=0.2, # zoom entre 0.8 et 1.2
        horizontal_flip=True, # retournement horizontal
        vertical_flip=False) # pas de retournement vertical

# Utilisation de la méthode flow_from_directory pour charger les images
train_generator = datagen.flow_from_directory(my_path,
        target_size=(IMG_SIZE, IMG_SIZE),
        batch_size=32,
        class_mode='binary')